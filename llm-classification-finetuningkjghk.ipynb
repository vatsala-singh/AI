{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:16:54.807907Z","iopub.execute_input":"2025-12-17T07:16:54.808679Z","iopub.status.idle":"2025-12-17T07:16:54.814419Z","shell.execute_reply.started":"2025-12-17T07:16:54.808652Z","shell.execute_reply":"2025-12-17T07:16:54.813616Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/llm-classification-finetuning/sample_submission.csv\n/kaggle/input/llm-classification-finetuning/train.csv\n/kaggle/input/llm-classification-finetuning/test.csv\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import re\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:16:55.089248Z","iopub.execute_input":"2025-12-17T07:16:55.089884Z","iopub.status.idle":"2025-12-17T07:16:55.093269Z","shell.execute_reply.started":"2025-12-17T07:16:55.089861Z","shell.execute_reply":"2025-12-17T07:16:55.092581Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"**Basic Text Statistics**","metadata":{}},{"cell_type":"code","source":"def text_stats(text):\n    text = text or \"\"\n    tokens = text.split()\n    sentences = re.split(r'[.!?]', text)\n    return {\n        \"n_chars\": len(text),\n        \"n_tokens\": len(tokens),\n        \"n_sentences\":len([s for s in sentences if len(s.strip())>0]),\n        \"avg_token_len\":np.mean([len(t) for t in tokens]) if tokens else 0,\n        \"punct_ratio\": sum(c in \".,;:!?\" for c in text)/(len(text)+1),\n        \"digit_ratio\": sum(c.isdigit() for c in text) / (len(text) + 1),\n        \"uppercase_ratio\": sum(c.isupper() for c in text) / (len(text) + 1),\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:16:55.563539Z","iopub.execute_input":"2025-12-17T07:16:55.563808Z","iopub.status.idle":"2025-12-17T07:16:55.569470Z","shell.execute_reply.started":"2025-12-17T07:16:55.563791Z","shell.execute_reply":"2025-12-17T07:16:55.568713Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def formatting_features(text):\n    text = text or \"\"\n\n    return {\n        \"has_bullets\": int(bool(re.search(r\"^\\s*[-*â€¢]\", text, re.MULTILINE))),\n        \"n_bullets\": len(re.findall(r\"^\\s*[-*â€¢]\", text, re.MULTILINE)),\n        \"has_code\": int(\"```\" in text or \"`\" in text),\n        \"n_code_blocks\": text.count(\"```\"),\n        \"n_urls\": len(re.findall(r\"http[s]?://\", text)),\n        \"has_steps\": int(bool(re.search(r\"\\b(step|first|second|third)\\b\", text.lower()))),\n        \"question_marks\": text.count(\"?\"),\n        \"exclamations\": text.count(\"!\"),\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:16:55.873152Z","iopub.execute_input":"2025-12-17T07:16:55.873545Z","iopub.status.idle":"2025-12-17T07:16:55.878088Z","shell.execute_reply.started":"2025-12-17T07:16:55.873527Z","shell.execute_reply":"2025-12-17T07:16:55.877399Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def fit_tfidf(df):\n    corpus = (\n        df[\"prompt\"].tolist()\n        + df[\"response_a\"].tolist()\n        + df[\"response_b\"].tolist()\n    )\n    tfidf = TfidfVectorizer(\n        ngram_range=(1,2),\n        max_features=50_000,\n        stop_words=\"english\"\n    )\n    tfidf.fit(corpus)\n    return tfidf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:12:17.580256Z","iopub.execute_input":"2025-12-17T07:12:17.580889Z","iopub.status.idle":"2025-12-17T07:12:17.584784Z","shell.execute_reply.started":"2025-12-17T07:12:17.580866Z","shell.execute_reply":"2025-12-17T07:12:17.584082Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def tfidf_similarity(tfidf, text1, text2):\n    vecs = tfidf.transform([text1, text2])\n    return cosine_similarity(vecs[0], vecs[1])[0][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:12:17.819984Z","iopub.execute_input":"2025-12-17T07:12:17.820687Z","iopub.status.idle":"2025-12-17T07:12:17.824349Z","shell.execute_reply.started":"2025-12-17T07:12:17.820648Z","shell.execute_reply":"2025-12-17T07:12:17.823693Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def build_response_features(df, response_col, prefix):\n    features = []\n\n    for text in df[response_col]:\n        stats = text_stats(text)\n        fmt = formatting_features(text)\n        features.append({**stats, **fmt})\n\n    feat_df = pd.DataFrame(features)\n    feat_df.columns = [f\"{prefix}_{c}\" for c in feat_df.columns]\n    return feat_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:16:58.803468Z","iopub.execute_input":"2025-12-17T07:16:58.803790Z","iopub.status.idle":"2025-12-17T07:16:58.809053Z","shell.execute_reply.started":"2025-12-17T07:16:58.803767Z","shell.execute_reply":"2025-12-17T07:16:58.808267Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def build_features(df):\n    df = df.copy()\n    # --- Response-level features ---\n    fa = build_response_features(df, \"response_a\", \"a\")\n    fb = build_response_features(df, \"response_b\", \"b\")\n    # --- Delta features ---\n    delta = fa.values - fb.values\n    delta_df = pd.DataFrame(\n        delta,\n        columns=[c.replace(\"a_\", \"delta_\") for c in fa.columns]\n    )\n    # --- TF-IDF similarity ---\n    tfidf = fit_tfidf(df)\n\n    df[\"sim_a_prompt\"] = [\n        tfidf_similarity(tfidf, p, a)\n        for p, a in zip(df[\"prompt\"], df[\"response_a\"])\n    ]\n    df[\"sim_b_prompt\"] = [\n        tfidf_similarity(tfidf, p, b)\n        for p, b in zip(df[\"prompt\"], df[\"response_b\"])\n    ]\n    df[\"delta_prompt_sim\"] = df[\"sim_a_prompt\"] - df[\"sim_b_prompt\"]\n    df[\"len_ratio\"] = (\n        (fa[\"a_n_tokens\"] + 1) / (fb[\"b_n_tokens\"] + 1)\n    )\n    # --- Model identity (encode later) ---\n    model_feats = df[[\"model_a\", \"model_b\"]]\n    # --- Final feature set ---\n    X = pd.concat(\n        [\n            fa,\n            fb,\n            delta_df,\n            df[\n                [\n                    \"sim_a_prompt\",\n                    \"sim_b_prompt\",\n                    \"delta_prompt_sim\",\n                    \"len_ratio\",\n                ]\n            ],\n            model_feats,\n        ],\n        axis=1,\n    )\n\n    return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:16:59.053804Z","iopub.execute_input":"2025-12-17T07:16:59.054455Z","iopub.status.idle":"2025-12-17T07:16:59.060770Z","shell.execute_reply.started":"2025-12-17T07:16:59.054431Z","shell.execute_reply":"2025-12-17T07:16:59.059935Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def build_target(df):\n    y = np.zeros(len(df))\n    y[df[\"winner_model_a\"] == 1] = 1.0\n    y[df[\"winner_model_b\"] == 1] = 0.0\n    y[df[\"winner_tie\"] == 1] = 0.5\n    return y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:17:06.569197Z","iopub.execute_input":"2025-12-17T07:17:06.569889Z","iopub.status.idle":"2025-12-17T07:17:06.573801Z","shell.execute_reply.started":"2025-12-17T07:17:06.569864Z","shell.execute_reply":"2025-12-17T07:17:06.573083Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def swap_augmentation(df, y):\n    df_swapped = df.copy()\n\n    df_swapped[\"response_a\"], df_swapped[\"response_b\"] = (\n        df[\"response_b\"],\n        df[\"response_a\"],\n    )\n    df_swapped[\"model_a\"], df_swapped[\"model_b\"] = (\n        df[\"model_b\"],\n        df[\"model_a\"],\n    )\n\n    y_swapped = 1 - y\n\n    df_aug = pd.concat([df, df_swapped], axis=0).reset_index(drop=True)\n    y_aug = np.concatenate([y, y_swapped])\n\n    return df_aug, y_aug","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:17:06.789167Z","iopub.execute_input":"2025-12-17T07:17:06.789861Z","iopub.status.idle":"2025-12-17T07:17:06.794321Z","shell.execute_reply.started":"2025-12-17T07:17:06.789835Z","shell.execute_reply":"2025-12-17T07:17:06.793568Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:17:07.176961Z","iopub.execute_input":"2025-12-17T07:17:07.177691Z","iopub.status.idle":"2025-12-17T07:17:07.181370Z","shell.execute_reply.started":"2025-12-17T07:17:07.177668Z","shell.execute_reply":"2025-12-17T07:17:07.180601Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"\nwith tf.device('/GPU:0'):\n    \n    df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\n    \n    y = build_target(df)\n    df_aug, y_aug = swap_augmentation(df, y)\n    \n    X = build_features(df_aug)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:24:08.979545Z","iopub.execute_input":"2025-12-17T07:24:08.979862Z","iopub.status.idle":"2025-12-17T07:32:33.431224Z","shell.execute_reply.started":"2025-12-17T07:24:08.979839Z","shell.execute_reply":"2025-12-17T07:32:33.430600Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"X.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:33:54.135898Z","iopub.execute_input":"2025-12-17T07:33:54.136176Z","iopub.status.idle":"2025-12-17T07:33:54.169596Z","shell.execute_reply.started":"2025-12-17T07:33:54.136156Z","shell.execute_reply":"2025-12-17T07:33:54.168895Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"   a_n_chars  a_n_tokens  a_n_sentences  a_avg_token_len  a_punct_ratio  \\\n0       4538         656             40         5.919207       0.020048   \n1       3114         531             21         4.854991       0.016051   \n2        921         138             10         5.659420       0.019523   \n3       3182         536             30         4.938433       0.019164   \n4       1300         230             11         4.630435       0.019985   \n\n   a_digit_ratio  a_uppercase_ratio  a_has_bullets  a_n_bullets  a_has_code  \\\n0       0.003966           0.013439              0            0           0   \n1       0.002889           0.008668              0            0           0   \n2       0.000000           0.017354              0            0           1   \n3       0.003770           0.018222              0            0           0   \n4       0.008455           0.031514              0            0           0   \n\n   ...  delta_n_urls  delta_has_steps  delta_question_marks  \\\n0  ...           0.0              0.0                   1.0   \n1  ...           0.0              0.0                   0.0   \n2  ...           0.0              0.0                   0.0   \n3  ...           0.0              0.0                   0.0   \n4  ...           0.0              0.0                   0.0   \n\n   delta_exclamations  sim_a_prompt  sim_b_prompt  delta_prompt_sim  \\\n0                 3.0      0.392832      0.293792          0.099040   \n1                 0.0      0.609627      0.597318          0.012309   \n2                 2.0      0.404646      0.336475          0.068171   \n3                 0.0      0.574644      0.553549          0.021095   \n4                 0.0      0.608045      0.730724         -0.122679   \n\n   len_ratio             model_a              model_b  \n0   3.204878  gpt-4-1106-preview           gpt-4-0613  \n1   0.930070           koala-13b           gpt-4-0613  \n2   0.494662  gpt-3.5-turbo-0613       mistral-medium  \n3   2.018797    llama-2-13b-chat  mistral-7b-instruct  \n4   1.878049           koala-13b   gpt-3.5-turbo-0314  \n\n[5 rows x 51 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>a_n_chars</th>\n      <th>a_n_tokens</th>\n      <th>a_n_sentences</th>\n      <th>a_avg_token_len</th>\n      <th>a_punct_ratio</th>\n      <th>a_digit_ratio</th>\n      <th>a_uppercase_ratio</th>\n      <th>a_has_bullets</th>\n      <th>a_n_bullets</th>\n      <th>a_has_code</th>\n      <th>...</th>\n      <th>delta_n_urls</th>\n      <th>delta_has_steps</th>\n      <th>delta_question_marks</th>\n      <th>delta_exclamations</th>\n      <th>sim_a_prompt</th>\n      <th>sim_b_prompt</th>\n      <th>delta_prompt_sim</th>\n      <th>len_ratio</th>\n      <th>model_a</th>\n      <th>model_b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4538</td>\n      <td>656</td>\n      <td>40</td>\n      <td>5.919207</td>\n      <td>0.020048</td>\n      <td>0.003966</td>\n      <td>0.013439</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>0.392832</td>\n      <td>0.293792</td>\n      <td>0.099040</td>\n      <td>3.204878</td>\n      <td>gpt-4-1106-preview</td>\n      <td>gpt-4-0613</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3114</td>\n      <td>531</td>\n      <td>21</td>\n      <td>4.854991</td>\n      <td>0.016051</td>\n      <td>0.002889</td>\n      <td>0.008668</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.609627</td>\n      <td>0.597318</td>\n      <td>0.012309</td>\n      <td>0.930070</td>\n      <td>koala-13b</td>\n      <td>gpt-4-0613</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>921</td>\n      <td>138</td>\n      <td>10</td>\n      <td>5.659420</td>\n      <td>0.019523</td>\n      <td>0.000000</td>\n      <td>0.017354</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.404646</td>\n      <td>0.336475</td>\n      <td>0.068171</td>\n      <td>0.494662</td>\n      <td>gpt-3.5-turbo-0613</td>\n      <td>mistral-medium</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3182</td>\n      <td>536</td>\n      <td>30</td>\n      <td>4.938433</td>\n      <td>0.019164</td>\n      <td>0.003770</td>\n      <td>0.018222</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.574644</td>\n      <td>0.553549</td>\n      <td>0.021095</td>\n      <td>2.018797</td>\n      <td>llama-2-13b-chat</td>\n      <td>mistral-7b-instruct</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1300</td>\n      <td>230</td>\n      <td>11</td>\n      <td>4.630435</td>\n      <td>0.019985</td>\n      <td>0.008455</td>\n      <td>0.031514</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.608045</td>\n      <td>0.730724</td>\n      <td>-0.122679</td>\n      <td>1.878049</td>\n      <td>koala-13b</td>\n      <td>gpt-3.5-turbo-0314</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 51 columns</p>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"import lightgbm as lgb\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T18:34:30.758825Z","iopub.execute_input":"2025-12-16T18:34:30.759444Z","iopub.status.idle":"2025-12-16T18:34:36.250932Z","shell.execute_reply.started":"2025-12-16T18:34:30.759421Z","shell.execute_reply":"2025-12-16T18:34:36.250363Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"#test data\ntest_df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\nX_test = build_features(test_df)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def encode_models(X_train, X_valid, cols=[\"model_a\", \"model_b\"]):\n    for c in cols:\n        le = LabelEncoder()\n        all_vals = pd.concat([X_train[c], X_valid[c]]).astype(str)\n        le.fit(all_vals)\n\n        X_train[c] = le.transform(X_train[c].astype(str))\n        X_valid[c] = le.transform(X_valid[c].astype(str))\n        X_test[c] = le.transform(X_test[c].astype(str))\n    return X_train, X_valid","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:23:54.583635Z","iopub.status.idle":"2025-12-17T07:23:54.583880Z","shell.execute_reply.started":"2025-12-17T07:23:54.583768Z","shell.execute_reply":"2025-12-17T07:23:54.583779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lgb_params = {\n    \"objective\": \"regression\",\n    \"metric\": \"rmse\",\n    \"learning_rate\": 0.03,\n    \"num_leaves\": 64,\n    \"max_depth\": -1,\n    \"min_data_in_leaf\": 50,\n    \"feature_fraction\": 0.8,\n    \"bagging_fraction\": 0.8,\n    \"bagging_freq\": 5,\n    \"lambda_l1\": 0.5,\n    \"lambda_l2\": 0.5,\n    \"verbosity\": -1,\n    \"seed\": 42,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T18:35:19.036544Z","iopub.execute_input":"2025-12-16T18:35:19.036826Z","iopub.status.idle":"2025-12-16T18:35:19.040948Z","shell.execute_reply.started":"2025-12-16T18:35:19.036807Z","shell.execute_reply":"2025-12-16T18:35:19.040250Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def train_lgb_oof(X, y, prompts, n_splits=5):\n    oof_preds = np.zeros(len(X))\n    models = []\n\n    gkf = GroupKFold(n_splits=n_splits)\n\n    for fold, (tr_idx, va_idx) in enumerate(gkf.split(X, y, groups=prompts)):\n        print(f\"\\nðŸ”¥ Fold {fold + 1}\")\n\n        X_tr, X_va = X.iloc[tr_idx].copy(), X.iloc[va_idx].copy()\n        y_tr, y_va = y[tr_idx], y[va_idx]\n\n        # Encode model identity\n        X_tr, X_va = encode_models(X_tr, X_va)\n\n        train_data = lgb.Dataset(X_tr, label=y_tr)\n        valid_data = lgb.Dataset(X_va, label=y_va)\n\n        model = lgb.train(\n            lgb_params,\n            train_data,\n            valid_sets=[valid_data],\n            num_boost_round=3000,\n            callbacks=[\n                lgb.early_stopping(100),\n                lgb.log_evaluation(200),\n            ],\n        )\n\n        preds = model.predict(X_va, num_iteration=model.best_iteration)\n        preds = np.clip(preds, 0.02, 0.98)\n\n        oof_preds[va_idx] = preds\n        models.append(model)\n\n        print(\n            \"Fold RMSE:\",\n            np.sqrt(np.mean((y_va - preds) ** 2)),\n        )\n\n    return oof_preds, models\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T18:35:38.693999Z","iopub.execute_input":"2025-12-16T18:35:38.694268Z","iopub.status.idle":"2025-12-16T18:35:38.700986Z","shell.execute_reply.started":"2025-12-16T18:35:38.694249Z","shell.execute_reply":"2025-12-16T18:35:38.700339Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# X, y_aug already built from feature engineering\nprompts = df_aug[\"prompt\"]\n\noof_lgb, lgb_models = train_lgb_oof(X, y_aug, prompts)\n\nprint(\"\\nâœ… Overall OOF RMSE:\",\n      np.sqrt(np.mean((y_aug - oof_lgb) ** 2)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T18:35:50.537774Z","iopub.execute_input":"2025-12-16T18:35:50.538215Z","iopub.status.idle":"2025-12-16T18:36:28.458802Z","shell.execute_reply.started":"2025-12-16T18:35:50.538189Z","shell.execute_reply":"2025-12-16T18:36:28.458137Z"}},"outputs":[{"name":"stdout","text":"\nðŸ”¥ Fold 1\nTraining until validation scores don't improve for 100 rounds\n[200]\tvalid_0's rmse: 0.384406\n[400]\tvalid_0's rmse: 0.383942\n[600]\tvalid_0's rmse: 0.383832\nEarly stopping, best iteration is:\n[500]\tvalid_0's rmse: 0.38372\nFold RMSE: 0.3837141828791263\n\nðŸ”¥ Fold 2\nTraining until validation scores don't improve for 100 rounds\n[200]\tvalid_0's rmse: 0.386393\n[400]\tvalid_0's rmse: 0.385658\nEarly stopping, best iteration is:\n[382]\tvalid_0's rmse: 0.385644\nFold RMSE: 0.38564225575798927\n\nðŸ”¥ Fold 3\nTraining until validation scores don't improve for 100 rounds\n[200]\tvalid_0's rmse: 0.384794\n[400]\tvalid_0's rmse: 0.383987\n[600]\tvalid_0's rmse: 0.383871\nEarly stopping, best iteration is:\n[540]\tvalid_0's rmse: 0.383807\nFold RMSE: 0.38379807445071246\n\nðŸ”¥ Fold 4\nTraining until validation scores don't improve for 100 rounds\n[200]\tvalid_0's rmse: 0.383608\n[400]\tvalid_0's rmse: 0.382734\nEarly stopping, best iteration is:\n[481]\tvalid_0's rmse: 0.382563\nFold RMSE: 0.3825621900379248\n\nðŸ”¥ Fold 5\nTraining until validation scores don't improve for 100 rounds\n[200]\tvalid_0's rmse: 0.383211\n[400]\tvalid_0's rmse: 0.382729\nEarly stopping, best iteration is:\n[490]\tvalid_0's rmse: 0.382572\nFold RMSE: 0.382572318751477\n\nâœ… Overall OOF RMSE: 0.3836594923078309\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"def format_submission(p):\n    return pd.DataFrame({\n        \"winner_model_a\": p,\n        \"winner_model_b\": 1 - p,\n        \"winner_tie\": np.zeros(len(p)),\n    })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T18:37:35.547683Z","iopub.execute_input":"2025-12-16T18:37:35.548557Z","iopub.status.idle":"2025-12-16T18:37:35.552724Z","shell.execute_reply.started":"2025-12-16T18:37:35.548530Z","shell.execute_reply":"2025-12-16T18:37:35.551825Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T18:46:56.551943Z","iopub.execute_input":"2025-12-16T18:46:56.552536Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lgb_models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T18:45:29.088216Z","iopub.execute_input":"2025-12-16T18:45:29.088509Z","iopub.status.idle":"2025-12-16T18:45:29.093440Z","shell.execute_reply.started":"2025-12-16T18:45:29.088461Z","shell.execute_reply":"2025-12-16T18:45:29.092936Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"[<lightgbm.basic.Booster at 0x78ffc371b390>,\n <lightgbm.basic.Booster at 0x78ffc3718c10>,\n <lightgbm.basic.Booster at 0x79000857b990>,\n <lightgbm.basic.Booster at 0x78ffe075a150>,\n <lightgbm.basic.Booster at 0x78ff9e55c290>]"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}