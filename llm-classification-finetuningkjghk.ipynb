{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpuV5e8","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T08:34:59.633127Z","iopub.execute_input":"2025-12-17T08:34:59.633400Z","iopub.status.idle":"2025-12-17T08:34:59.637118Z","shell.execute_reply.started":"2025-12-17T08:34:59.633380Z","shell.execute_reply":"2025-12-17T08:34:59.636467Z"}},"outputs":[],"execution_count":46},{"cell_type":"markdown","source":"**Basic Text Statistics**","metadata":{}},{"cell_type":"code","source":"def text_stats(text):\n    text = text or \"\"\n    tokens = text.split()\n    sentences = re.split(r'[.!?]', text)\n    return {\n        \"n_chars\": len(text),\n        \"n_tokens\": len(tokens),\n        \"n_sentences\":len([s for s in sentences if len(s.strip())>0]),\n        \"avg_token_len\":np.mean([len(t) for t in tokens]) if tokens else 0,\n        \"punct_ratio\": sum(c in \".,;:!?\" for c in text)/(len(text)+1),\n        \"digit_ratio\": sum(c.isdigit() for c in text) / (len(text) + 1),\n        \"uppercase_ratio\": sum(c.isupper() for c in text) / (len(text) + 1),\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T08:35:52.335109Z","iopub.execute_input":"2025-12-17T08:35:52.335836Z","iopub.status.idle":"2025-12-17T08:35:52.341132Z","shell.execute_reply.started":"2025-12-17T08:35:52.335809Z","shell.execute_reply":"2025-12-17T08:35:52.340299Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"def formatting_features(text):\n    text = text or \"\"\n\n    return {\n        \"has_bullets\": int(bool(re.search(r\"^\\s*[-*â€¢]\", text, re.MULTILINE))),\n        \"n_bullets\": len(re.findall(r\"^\\s*[-*â€¢]\", text, re.MULTILINE)),\n        \"has_code\": int(\"```\" in text or \"`\" in text),\n        \"n_code_blocks\": text.count(\"```\"),\n        \"n_urls\": len(re.findall(r\"http[s]?://\", text)),\n        \"has_steps\": int(bool(re.search(r\"\\b(step|first|second|third)\\b\", text.lower()))),\n        \"question_marks\": text.count(\"?\"),\n        \"exclamations\": text.count(\"!\"),\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T08:35:53.238828Z","iopub.execute_input":"2025-12-17T08:35:53.239139Z","iopub.status.idle":"2025-12-17T08:35:53.244901Z","shell.execute_reply.started":"2025-12-17T08:35:53.239117Z","shell.execute_reply":"2025-12-17T08:35:53.244013Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"def fit_tfidf(df):\n    corpus = (\n        df[\"prompt\"].tolist()\n        + df[\"response_a\"].tolist()\n        + df[\"response_b\"].tolist()\n    )\n    tfidf = TfidfVectorizer(\n        ngram_range=(1,2),\n        max_features=50_000,\n        stop_words=\"english\"\n    )\n    tfidf.fit(corpus)\n    return tfidf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T08:35:54.016060Z","iopub.execute_input":"2025-12-17T08:35:54.016338Z","iopub.status.idle":"2025-12-17T08:35:54.020538Z","shell.execute_reply.started":"2025-12-17T08:35:54.016308Z","shell.execute_reply":"2025-12-17T08:35:54.019994Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"def tfidf_similarity(tfidf, text1, text2):\n    vecs = tfidf.transform([text1, text2])\n    return cosine_similarity(vecs[0], vecs[1])[0][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T08:36:00.893690Z","iopub.execute_input":"2025-12-17T08:36:00.893981Z","iopub.status.idle":"2025-12-17T08:36:00.897977Z","shell.execute_reply.started":"2025-12-17T08:36:00.893960Z","shell.execute_reply":"2025-12-17T08:36:00.897178Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"def build_response_features(df, response_col, prefix):\n    features = []\n\n    for text in df[response_col]:\n        stats = text_stats(text)\n        fmt = formatting_features(text)\n        features.append({**stats, **fmt})\n\n    feat_df = pd.DataFrame(features)\n    feat_df.columns = [f\"{prefix}_{c}\" for c in feat_df.columns]\n    return feat_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T08:36:01.227561Z","iopub.execute_input":"2025-12-17T08:36:01.228251Z","iopub.status.idle":"2025-12-17T08:36:01.232690Z","shell.execute_reply.started":"2025-12-17T08:36:01.228227Z","shell.execute_reply":"2025-12-17T08:36:01.232067Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"def build_features(df):\n    df = df.copy()\n    # --- Response-level features ---\n    fa = build_response_features(df, \"response_a\", \"a\")\n    fb = build_response_features(df, \"response_b\", \"b\")\n    # --- Delta features ---\n    delta = fa.values - fb.values\n    delta_df = pd.DataFrame(\n        delta,\n        columns=[c.replace(\"a_\", \"delta_\") for c in fa.columns]\n    )\n    # --- TF-IDF similarity ---\n    tfidf = fit_tfidf(df)\n\n    df[\"sim_a_prompt\"] = [\n        tfidf_similarity(tfidf, p, a)\n        for p, a in zip(df[\"prompt\"], df[\"response_a\"])\n    ]\n    df[\"sim_b_prompt\"] = [\n        tfidf_similarity(tfidf, p, b)\n        for p, b in zip(df[\"prompt\"], df[\"response_b\"])\n    ]\n    df[\"delta_prompt_sim\"] = df[\"sim_a_prompt\"] - df[\"sim_b_prompt\"]\n    df[\"len_ratio\"] = (\n        (fa[\"a_n_tokens\"] + 1) / (fb[\"b_n_tokens\"] + 1)\n    )\n    # --- Model identity (encode later) ---\n    model_feats = df[[\"model_a\", \"model_b\"]]\n    # --- Final feature set ---\n    X = pd.concat(\n        [\n            fa,\n            fb,\n            delta_df,\n            df[\n                [\n                    \"sim_a_prompt\",\n                    \"sim_b_prompt\",\n                    \"delta_prompt_sim\",\n                    \"len_ratio\",\n                ]\n            ],\n            model_feats,\n        ],\n        axis=1,\n    )\n\n    return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T08:36:02.734802Z","iopub.execute_input":"2025-12-17T08:36:02.735334Z","iopub.status.idle":"2025-12-17T08:36:02.741210Z","shell.execute_reply.started":"2025-12-17T08:36:02.735311Z","shell.execute_reply":"2025-12-17T08:36:02.740502Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"def build_target(df):\n    y = np.zeros(len(df))\n    y[df[\"winner_model_a\"] == 1] = 1.0\n    y[df[\"winner_model_b\"] == 1] = 0.0\n    y[df[\"winner_tie\"] == 1] = 0.5\n    return y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:17:06.569197Z","iopub.execute_input":"2025-12-17T07:17:06.569889Z","iopub.status.idle":"2025-12-17T07:17:06.573801Z","shell.execute_reply.started":"2025-12-17T07:17:06.569864Z","shell.execute_reply":"2025-12-17T07:17:06.573083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def swap_augmentation(df, y):\n    df_swapped = df.copy()\n\n    df_swapped[\"response_a\"], df_swapped[\"response_b\"] = (\n        df[\"response_b\"],\n        df[\"response_a\"],\n    )\n    df_swapped[\"model_a\"], df_swapped[\"model_b\"] = (\n        df[\"model_b\"],\n        df[\"model_a\"],\n    )\n\n    y_swapped = 1 - y\n\n    df_aug = pd.concat([df, df_swapped], axis=0).reset_index(drop=True)\n    y_aug = np.concatenate([y, y_swapped])\n\n    return df_aug, y_aug","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T08:01:01.838703Z","iopub.execute_input":"2025-12-17T08:01:01.839296Z","iopub.status.idle":"2025-12-17T08:01:01.843807Z","shell.execute_reply.started":"2025-12-17T08:01:01.839275Z","shell.execute_reply":"2025-12-17T08:01:01.843106Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:17:07.176961Z","iopub.execute_input":"2025-12-17T07:17:07.177691Z","iopub.status.idle":"2025-12-17T07:17:07.181370Z","shell.execute_reply.started":"2025-12-17T07:17:07.177668Z","shell.execute_reply":"2025-12-17T07:17:07.180601Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nwith tf.device('/GPU:0'):\n    \n    df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\n    \n    y = build_target(df)\n    df_aug, y_aug = swap_augmentation(df, y)\n    \n    X = build_features(df_aug)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:24:08.979545Z","iopub.execute_input":"2025-12-17T07:24:08.979862Z","iopub.status.idle":"2025-12-17T07:32:33.431224Z","shell.execute_reply.started":"2025-12-17T07:24:08.979839Z","shell.execute_reply":"2025-12-17T07:32:33.430600Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:33:54.135898Z","iopub.execute_input":"2025-12-17T07:33:54.136176Z","iopub.status.idle":"2025-12-17T07:33:54.169596Z","shell.execute_reply.started":"2025-12-17T07:33:54.136156Z","shell.execute_reply":"2025-12-17T07:33:54.168895Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import lightgbm as lgb\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:34:46.641377Z","iopub.execute_input":"2025-12-17T07:34:46.641654Z","iopub.status.idle":"2025-12-17T07:34:53.011520Z","shell.execute_reply.started":"2025-12-17T07:34:46.641634Z","shell.execute_reply":"2025-12-17T07:34:53.010965Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#test data\nwith tf.device('/GPU:0'):\n    test_df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\n    X_test = build_features(test_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T07:39:05.864601Z","iopub.execute_input":"2025-12-17T07:39:05.865137Z","iopub.status.idle":"2025-12-17T07:43:35.428028Z","shell.execute_reply.started":"2025-12-17T07:39:05.865112Z","shell.execute_reply":"2025-12-17T07:43:35.427406Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T08:01:37.056018Z","iopub.execute_input":"2025-12-17T08:01:37.056707Z","iopub.status.idle":"2025-12-17T08:01:37.085611Z","shell.execute_reply.started":"2025-12-17T08:01:37.056686Z","shell.execute_reply":"2025-12-17T08:01:37.085041Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def encode_models(X_train, X_valid, cols=[\"model_a\", \"model_b\"]):\n    for c in cols:\n        le = LabelEncoder()\n        all_vals = pd.concat([X_train[c], X_valid[c], X_test[c]]).astype(str)\n        le.fit(all_vals)\n\n        X_train[c] = le.transform(X_train[c].astype(str))\n        X_valid[c] = le.transform(X_valid[c].astype(str))\n        X_test[c] = le.transform(X_test[c].astype(str))\n    return X_train, X_valid","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T08:02:27.963203Z","iopub.execute_input":"2025-12-17T08:02:27.963751Z","iopub.status.idle":"2025-12-17T08:02:27.968093Z","shell.execute_reply.started":"2025-12-17T08:02:27.963710Z","shell.execute_reply":"2025-12-17T08:02:27.967511Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lgb_params = {\n    \"objective\": \"regression\",\n    \"metric\": \"rmse\",\n    \"learning_rate\": 0.03,\n    \"num_leaves\": 64,\n    \"max_depth\": -1,\n    \"min_data_in_leaf\": 50,\n    \"feature_fraction\": 0.8,\n    \"bagging_fraction\": 0.8,\n    \"bagging_freq\": 5,\n    \"lambda_l1\": 0.5,\n    \"lambda_l2\": 0.5,\n    \"verbosity\": -1,\n    \"seed\": 42,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T08:00:01.658885Z","iopub.execute_input":"2025-12-17T08:00:01.659567Z","iopub.status.idle":"2025-12-17T08:00:01.663400Z","shell.execute_reply.started":"2025-12-17T08:00:01.659544Z","shell.execute_reply":"2025-12-17T08:00:01.662657Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_lgb_oof(X, y, prompts, n_splits=5):\n    oof_preds = np.zeros(len(X))\n    models = []\n\n    gkf = GroupKFold(n_splits=n_splits)\n\n    for fold, (tr_idx, va_idx) in enumerate(gkf.split(X, y, groups=prompts)):\n        print(f\"\\nðŸ”¥ Fold {fold + 1}\")\n\n        X_tr, X_va = X.iloc[tr_idx].copy(), X.iloc[va_idx].copy()\n        y_tr, y_va = y[tr_idx], y[va_idx]\n\n        # Encode model identity\n        X_tr, X_va = encode_models(X_tr, X_va)\n\n        train_data = lgb.Dataset(X_tr, label=y_tr)\n        valid_data = lgb.Dataset(X_va, label=y_va)\n\n        model = lgb.train(\n            lgb_params,\n            train_data,\n            valid_sets=[valid_data],\n            num_boost_round=3000,\n            callbacks=[\n                lgb.early_stopping(100),\n                lgb.log_evaluation(200),\n            ],\n        )\n\n        preds = model.predict(X_va, num_iteration=model.best_iteration)\n        preds = np.clip(preds, 0.02, 0.98)\n\n        oof_preds[va_idx] = preds\n        models.append(model)\n\n        print(\n            \"Fold RMSE:\",\n            np.sqrt(np.mean((y_va - preds) ** 2)),\n        )\n\n    return oof_preds, models\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T08:02:36.296317Z","iopub.execute_input":"2025-12-17T08:02:36.296586Z","iopub.status.idle":"2025-12-17T08:02:36.307913Z","shell.execute_reply.started":"2025-12-17T08:02:36.296565Z","shell.execute_reply":"2025-12-17T08:02:36.307176Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# X, y_aug already built from feature engineering\nwith tf.device('/GPU:0'):\n    prompts = df_aug[\"prompt\"]\n\n    oof_lgb, lgb_models = train_lgb_oof(X, y_aug, prompts)\n\n    print(\"\\nâœ… Overall OOF RMSE:\",\n      np.sqrt(np.mean((y_aug - oof_lgb) ** 2)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T08:02:44.588261Z","iopub.execute_input":"2025-12-17T08:02:44.588525Z","iopub.status.idle":"2025-12-17T08:03:21.480241Z","shell.execute_reply.started":"2025-12-17T08:02:44.588506Z","shell.execute_reply":"2025-12-17T08:03:21.479750Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_pred = lgb_models[4].predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T08:36:07.296099Z","iopub.execute_input":"2025-12-17T08:36:07.296834Z","iopub.status.idle":"2025-12-17T08:36:07.913693Z","shell.execute_reply.started":"2025-12-17T08:36:07.296809Z","shell.execute_reply":"2025-12-17T08:36:07.913107Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"test_pred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T08:36:10.253404Z","iopub.execute_input":"2025-12-17T08:36:10.253636Z","iopub.status.idle":"2025-12-17T08:36:10.258579Z","shell.execute_reply.started":"2025-12-17T08:36:10.253620Z","shell.execute_reply":"2025-12-17T08:36:10.257998Z"}},"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"array([0.61589651, 0.55476302, 0.46846517, ..., 0.54120125, 0.55018336,\n       0.59073206])"},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"submission = pd.DataFrame({\n    \"winner_model_a\": test_pred,\n    \"winner_model_b\": 1 - test_pred,\n    \"winner_tie\": np.zeros(len(test_pred))\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T08:36:11.527408Z","iopub.execute_input":"2025-12-17T08:36:11.527940Z","iopub.status.idle":"2025-12-17T08:36:11.532390Z","shell.execute_reply.started":"2025-12-17T08:36:11.527919Z","shell.execute_reply":"2025-12-17T08:36:11.531709Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"submission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T08:36:15.532620Z","iopub.execute_input":"2025-12-17T08:36:15.533320Z","iopub.status.idle":"2025-12-17T08:36:15.542473Z","shell.execute_reply.started":"2025-12-17T08:36:15.533295Z","shell.execute_reply":"2025-12-17T08:36:15.541867Z"}},"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"       winner_model_a  winner_model_b  winner_tie\n0            0.615897        0.384103         0.0\n1            0.554763        0.445237         0.0\n2            0.468465        0.531535         0.0\n3            0.541663        0.458337         0.0\n4            0.388269        0.611731         0.0\n...               ...             ...         ...\n57472        0.615788        0.384212         0.0\n57473        0.531420        0.468580         0.0\n57474        0.541201        0.458799         0.0\n57475        0.550183        0.449817         0.0\n57476        0.590732        0.409268         0.0\n\n[57477 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>winner_model_a</th>\n      <th>winner_model_b</th>\n      <th>winner_tie</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.615897</td>\n      <td>0.384103</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.554763</td>\n      <td>0.445237</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.468465</td>\n      <td>0.531535</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.541663</td>\n      <td>0.458337</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.388269</td>\n      <td>0.611731</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>57472</th>\n      <td>0.615788</td>\n      <td>0.384212</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>57473</th>\n      <td>0.531420</td>\n      <td>0.468580</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>57474</th>\n      <td>0.541201</td>\n      <td>0.458799</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>57475</th>\n      <td>0.550183</td>\n      <td>0.449817</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>57476</th>\n      <td>0.590732</td>\n      <td>0.409268</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>57477 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T08:36:40.167669Z","iopub.execute_input":"2025-12-17T08:36:40.167930Z","iopub.status.idle":"2025-12-17T08:36:40.377269Z","shell.execute_reply.started":"2025-12-17T08:36:40.167912Z","shell.execute_reply":"2025-12-17T08:36:40.376553Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"# def format_submission(p):\n#     return pd.DataFrame({\n#         \"winner_model_a\": p,\n#         \"winner_model_b\": 1 - p,\n#         \"winner_tie\": np.zeros(len(p)),\n#     })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T18:37:35.547683Z","iopub.execute_input":"2025-12-16T18:37:35.548557Z","iopub.status.idle":"2025-12-16T18:37:35.552724Z","shell.execute_reply.started":"2025-12-16T18:37:35.548530Z","shell.execute_reply":"2025-12-16T18:37:35.551825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T18:46:56.551943Z","iopub.execute_input":"2025-12-16T18:46:56.552536Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T18:45:29.088216Z","iopub.execute_input":"2025-12-16T18:45:29.088509Z","iopub.status.idle":"2025-12-16T18:45:29.093440Z","shell.execute_reply.started":"2025-12-16T18:45:29.088461Z","shell.execute_reply":"2025-12-16T18:45:29.092936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}